# ğŸ“ README.md

<p align="center">
  <img src="logo.png" alt="Logo do Projeto" width="300"/>
</p>

## ğŸ–ï¸ Aprendizado Interativo por Gestos â€“ Alfabeto em Libras

Este projeto tem como objetivo ensinar o alfabeto em Libras (LÃ­ngua Brasileira de Sinais) de forma interativa utilizando reconhecimento de gestos com MediaPipe, OpenCV e um modelo de Machine Learning treinado com vÃ­deos reais de cada letra.

---

## ğŸ“Œ Funcionalidades
- ğŸ“· Interface grÃ¡fica intuitiva com Tkinter
- ğŸ§  Reconhecimento de gestos da mÃ£o em tempo real
- ğŸ”  ExibiÃ§Ã£o de uma letra do alfabeto e um vÃ­deo de referÃªncia
- âœ… Feedback sonoro e visual ao reconhecer corretamente
- ğŸ”Š NarraÃ§Ã£o automÃ¡tica da letra
- â­ï¸ AvanÃ§o automÃ¡tico para a prÃ³xima letra apÃ³s o acerto
- ğŸ” Treinamento do modelo com dados extraÃ­dos de vÃ­deos personalizados

---

## ğŸ—‚ï¸ Estrutura dos Arquivos

- `contarDedos.py` â€” Coleta os pontos das mÃ£os a partir dos vÃ­deos e salva em um `.csv`
- `treinarIA.py` â€” Treina o modelo KNN com os dados extraÃ­dos
- `reconhecerLetra.py` â€” Interface grÃ¡fica com reconhecimento em tempo real
- `modelo_letras_knn.pkl` â€” Arquivo gerado com o modelo treinado
- `videos/` â€” Pasta com os vÃ­deos de cada letra (ex: `aSm_Prog001.mp4`, `bSm_Prog001.mp4`, ...)
- `dados_csv/letras.csv` â€” CSV com os pontos da mÃ£o e o rÃ³tulo da letra
- `acerto.mp3` â€” Som de feedback positivo

---

## ğŸ“¦ Requisitos

- Python 3.8+
- OpenCV
- MediaPipe
- Scikit-learn
- Pandas
- Tkinter (incluÃ­do no Python)
- joblib
- pyttsx3
- playsound
- Pillow

Instale com:
```bash
pip install opencv-python mediapipe scikit-learn pandas pyttsx3 playsound pillow
```

---

## â–¶ï¸ Como Rodar

1. Adicione vÃ­deos curtos dos gestos em `videos/`, com nomes como `aSm_Prog001.mp4`, `bSm_Prog001.mp4`, etc.
2. Execute `contarDedos.py` para gerar os dados:
```bash
python contarDedos.py
```
3. Treine o modelo:
```bash
python treinarIA.py
```
4. Rode o sistema interativo:
```bash
python reconhecerLetra.py
```

---

## ğŸ§  Como Funciona

1. A cÃ¢mera captura a imagem da mÃ£o do usuÃ¡rio.
2. O MediaPipe localiza os 21 pontos da mÃ£o.
3. Esses pontos sÃ£o passados para o modelo KNN treinado.
4. O sistema compara o gesto com os dados das letras.
5. Se acertar:
   - A interface mostra "Correto!"
   - Um som de acerto Ã© tocado
   - A voz narra a prÃ³xima letra
   - O sistema avanÃ§a automaticamente

---

## ğŸŒ Impacto na Ãrea

Esta aplicaÃ§Ã£o promove acessibilidade, inclusÃ£o e aprendizado personalizado da LÃ­ngua Brasileira de Sinais. 
Ela pode ser usada em:

- Escolas de educaÃ§Ã£o bilÃ­ngue e inclusiva
- Centros de reabilitaÃ§Ã£o auditiva
- Ambientes educacionais interativos e museus
- Plataformas de ensino remoto

Com baixo custo e alta interatividade, permite que crianÃ§as, jovens e adultos aprendam LIBRAS de forma divertida e eficaz.

---

## ğŸ“¸ Exemplo Visual

- WebCam + VÃ­deo lado a lado
- Pontos da mÃ£o desenhados com cores vibrantes

---

## Resultados
<p align="center">
  <img src="contarDedos.png" alt="Salvar dados - resultado" width="300"/>
</p>
<p align="center">
  <img src="treinarIA.png" alt="Resultado do treinamento" width="300"/>
</p>
<p align="center">
  <img src="telaInicial.png" alt="PÃ¡gina inicial da aplicaÃ§Ã£o" width="300"/>
</p>
<p align="center">
  <img src="teste.png" alt="Letra A - Teste" width="300"/>
</p>

## âœ¨ Melhorias Futuras

- Adicionar reconhecimento de palavras completas
- Treinamento com mais vÃ­deos e mais usuÃ¡rios
- Suporte a mÃºltiplas mÃ£os
- ImplementaÃ§Ã£o em versÃ£o mobile

---

## ğŸ‘¤ Autoria
Desenvolvido por VitÃ³ria Arruda Andrade, 2025.

---

âœ… Status: Funcional e testado.

ğŸ§ª AcurÃ¡cia Atual: Aproximadamente 81%

ğŸ“ LicenÃ§a: Livre para fins educacionais
